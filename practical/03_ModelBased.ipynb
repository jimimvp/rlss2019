{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5eeje4O8fviH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model-Based Reinforcement Learning\n",
    "\n",
    "## Principle\n",
    "We consider the optimal control problem of an MDP with a **known** reward function $R$ and subject to **unknown deterministic** dynamics $s_{t+1} = f(s_t, a_t)$:\n",
    "\n",
    "$$\\max_{(a_0,a_1,\\dotsc)} \\sum_{t=0}^\\infty \\gamma^t R(s_t,a_t)$$\n",
    "\n",
    "In **model-based reinforcement learning**, this problem is solved in **two steps**:\n",
    "1. **Model learning**:\n",
    "We learn a model of the dynamics $f_\\theta \\simeq f$ through regression on interaction data.\n",
    "2. **Planning**:\n",
    "We leverage the dynamics model $f_\\theta$ to compute the optimal trajectory $$\\max_{(a_0,a_1,\\dotsc)} \\sum_{t=0}^\\infty \\gamma^t R(\\hat{s}_t,a_t)$$ following the learnt dynamics $\\hat{s}_{t+1} = f_\\theta(\\hat{s}_t, a_t)$.\n",
    "\n",
    "(We can easily extend to unknown rewards and stochastic dynamics, but we consider the simpler case in this notebook for ease of presentation)\n",
    "\n",
    "\n",
    "## Motivation\n",
    "\n",
    "### Sparse rewards\n",
    "* In model-free reinforcement learning, we only obtain a reinforcement signal when encountering rewards. In environment with **sparse rewards**, the chance of obtaining a reward randomly is **negligible**, which prevents any learning.\n",
    "* However, even in the **absence of rewards** we still receive a **stream of state transition data**. We can exploit this data to learn about the task at hand.\n",
    "\n",
    "### Complexity of the policy/value vs dynamics:\n",
    "Is it easier to decide which action is best, or to predict what is going to happen?\n",
    "* Some problems can have **complex dynamics** but a **simple optimal policy or value function**. For instance, consider the problem of learning to swim. Predicting the movement requires understanding fluid dynamics and vortices while the optimal policy simply consists in moving the limbs in sync.\n",
    "* Conversely, other problems can have **simple dynamics** but **complex policies/value functions**. Think of the game of Go, its rules are simplistic (placing a stone merely changes the board state at this location) but the corresponding optimal policy is very complicated.\n",
    "\n",
    "Intuitively, model-free RL should be applied to the first category of problems and model-based RL to the second category.\n",
    "\n",
    "### Inductive bias\n",
    "Oftentimes, real-world problems exhibit a particular **structure**: for instance, any problem involving motion of physical objects will be **continuous**. It can also be **smooth**, **invariant** to translations, etc. This knowledge can then be incorporated in machine learning models to foster efficient learning. In contrast, there can often be **discontinuities** in the policy decisions or value function: e.g. think of a collision vs near-collision state.\n",
    "\n",
    "###  Sample efficiency\n",
    "Overall, it is generally recognized that model-based approaches tend to **learn faster** than model-free techniques (see e.g. [[Sutton, 1990]](http://papersdb.cs.ualberta.ca/~papersdb/uploaded_files/paper_p160-sutton.pdf.stjohn)).\n",
    "\n",
    "### Interpretability\n",
    "In real-world applications, we may want to know **how a policy will behave before actually executing it**, for instance for **safety-check** purposes. However, model-free reinforcement learning only recommends which action to take at current time without being able to predict its consequences. In order to obtain the trajectory, we have no choice but executing the policy. In stark contrast, model-based methods a more interpretable in the sense that we can probe the policy for its intended (and predicted) trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-oVNY_KTw6R"
   },
   "source": [
    "## Our challenge: Automated Parking System\n",
    "\n",
    "We consider the **parking-v0** task of the [highway-env](https://github.com/eleurent/highway-env) environment. It is a **goal-conditioned continuous control** task where an agent **drives a car** by controlling the gaz pedal and steering angle and must **park in a given location** with the appropriate heading.\n",
    "\n",
    "This MDP has several properties wich justifies using model-based methods:\n",
    "* The policy/value is highly dependent on the goal which adds a significant level of complexity to a model-free learning process, whereas the dynamics are completely independent of the goal and hence can be simpler to learn.\n",
    "* In the context of an industrial application, we can reasonably expect for safety concerns that the planned trajectory is required to be known in advance, before execution.\n",
    "\n",
    "###  Warming up\n",
    "We start with a few useful installs and imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYfRuXZtRwxD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove \" > /dev/null 2>&1\" to see what is going on under the hood\"\"\"\n",
    "# Install environment and visualization dependencies \n",
    "!pip install git+https://github.com/eleurent/highway-env#egg=highway-env  > /dev/null 2>&1\n",
    "#!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "#!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzMSuJEOfviP",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "import gym\n",
    "import highway_env\n",
    "\n",
    "# Models and computation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "# torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tnrange\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "from gym.wrappers import Monitor\n",
    "import base64\n",
    "\n",
    "# IO\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2Bu_Pqop0E7"
   },
   "source": [
    "We also define a simple helper function for visualization of episodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "so7yH4ucyB-3"
   },
   "outputs": [
    {
     "ename": "XStartTimeoutError",
     "evalue": "Failed to start X on display \":1001\" (xdpyinfo check failed).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXStartTimeoutError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-aeb4ce06167d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"video\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/pyvirtualdisplay/abstractdisplay.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Failed to start X on display \"%s\" (xdpyinfo check failed).'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXStartTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXStartTimeoutError\u001b[0m: Failed to start X on display \":1001\" (xdpyinfo check failed)."
     ]
    }
   ],
   "source": [
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "def show_videos(path=\"video\"):\n",
    "    html = []\n",
    "    for mp4 in Path(path).glob(\"*.mp4\"):\n",
    "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
    "        html.append('''<video alt=\"{}\" autoplay \n",
    "                      loop controls style=\"height: 400px;\">\n",
    "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(mp4, video_b64.decode('ascii')))\n",
    "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFtBY6JSqPFa"
   },
   "source": [
    "### Let's try it!\n",
    "\n",
    "Make the environment, and run an episode with random actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKZt9Cb1rJ6n"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-99bc75852441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mshow_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/highway_env/envs/parking_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;34m\"steering\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEERING_RANGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         })\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/highway_env/envs/common/abstract.py\u001b[0m in \u001b[0;36m_simulate\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# Automatically render intermediate simulation steps if a viewer has been launched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automatic_rendering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# Stop at terminal states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/highway_env/envs/common/abstract.py\u001b[0m in \u001b[0;36m_automatic_rendering\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_rendering_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrendering_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/highway_env/envs/common/abstract.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# If the frame has already been rendered, do nothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_update_rendering\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/highway_env/envs/common/graphics.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim_surface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIMULATION_FREQUENCY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make(\"parking-v0\")\n",
    "env = Monitor(env, './video', force=True, video_callable=lambda episode: True)\n",
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "env.close()\n",
    "show_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewG5f_essAS0"
   },
   "source": [
    "The environment is a `GoalEnv`, which means the agent receives a dictionary containing both the current `observation` and the `desired_goal` that conditions its policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIC98mGhr7v6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation format: {'observation': array([-0.22440158,  0.36577995, -0.26734558,  1.12603641,  0.2310004 ,\n",
      "       -0.97295366]), 'achieved_goal': array([-0.22440158,  0.36577995, -0.26734558,  1.12603641,  0.2310004 ,\n",
      "       -0.97295366]), 'desired_goal': array([2.600000e-01, 1.400000e-01, 0.000000e+00, 0.000000e+00,\n",
      "       6.123234e-17, 1.000000e+00])}\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation format:\", obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "voagCILztJ3J"
   },
   "source": [
    "There is also an `achieved_goal` that won't be useful here (it only serves when the state and goal spaces are different, as a projection from the observation to the goal space).\n",
    "\n",
    "Alright! We are now ready to apply the model-based reinforcement learning paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2PuVAvyfvib",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experience collection\n",
    "First, we randomly interact with the environment to produce a batch of experiences \n",
    "\n",
    "$$D = \\{s_t, a_t, s_{t+1}\\}_{t\\in[1,N]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvUYSL7sfvie",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample transition: Transition(state=tensor([ 0.0000,  0.0000,  0.0000, -0.0000,  0.1006, -0.9949],\n",
      "       dtype=torch.float64), action=tensor([-0.9281,  0.4923], dtype=torch.float64), next_state=tensor([-6.1573e-05,  6.1567e-04, -1.7748e-02,  1.8477e-01,  9.5614e-02,\n",
      "        -9.9542e-01], dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "Transition = namedtuple('Transition', ['state', 'action', 'next_state'])\n",
    "def tt(x):\n",
    "    return torch.from_numpy(x).double()\n",
    "\n",
    "class OrnsteinUhlenbeck():\n",
    "    def __init__(self, size, nmin=-.5, nmax=0.5, alow=-1, ahigh=1):\n",
    "        self.n = np.zeros(size)\n",
    "        self.std = 0.4\n",
    "        self.nmin = nmin\n",
    "        self.nmax = nmax\n",
    "        self.alow = alow\n",
    "        self.ahigh = ahigh\n",
    "        self.size = size\n",
    "        \n",
    "    def __call__(self):\n",
    "        self.n += np.clip(self.n + np.random.normal(0, self.std, self.size), self.nmin, self.nmax)\n",
    "        return self.n\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x = 0\n",
    "        \n",
    "\n",
    "def collect_interaction_data(env, size):\n",
    "    \"\"\"\n",
    "        QUESTION 1: Collect a dataset of random interaction with the environment.\n",
    "        \n",
    "        1. The env.action_space has a useful sample() method to generate independent uniform noise\n",
    "        2. States and actions should be cast as torch.Tensor, and stored into Transition tuples.\n",
    "        3. (Optional): In order to improve exploration, some kind of temporal consistent noise should be used.\n",
    "          A high-frequency noise quickly cancels itself out and will not be able to explore very deeply. \n",
    "          Holding an action for a longer time enables to build-up velocity and explore further.\n",
    "          Ornstein-Uhlenbeck noise processes are often used for continuous control tasks, but here a simple\n",
    "          action repeat strategy will be enough.\n",
    "        \n",
    "    :param env: an OpenAI Gym environment\n",
    "    :param size: the desired number of transitions \n",
    "    :return: a list of Transitions\n",
    "    \"\"\"\n",
    "    transitions = []\n",
    "    nmin = env.action_space.low\n",
    "    \n",
    "    ou_process = OrnsteinUhlenbeck(2)\n",
    "    while len(transitions) < size:\n",
    "        o = env.reset()\n",
    "        ou_process.reset()\n",
    "        d = False\n",
    "        a = a_start = env.action_space.sample()\n",
    "        while not d:\n",
    "            a = np.clip(a + ou_process(), env.action_space.low, env.action_space.high)\n",
    "            #a = env.action_space.sample()\n",
    "            o_next, r, d, inf = env.step(a)\n",
    "            transitions.append(Transition(state=tt(o['observation']), action=tt(a), next_state=tt(o_next['observation'])))\n",
    "            o = o_next\n",
    "    return transitions\n",
    "\n",
    "data_size = 5000\n",
    "data = collect_interaction_data(env, size=data_size)\n",
    "\n",
    "# the code below will check that collect_interaction_data implementation is correct-ish\n",
    "assert isinstance(data, list) and len(data) == data_size, \"return value should be a list of length data_size\"\n",
    "assert isinstance(data[0], Transition), \"return value should be a list whose elements are Transition tuples\"\n",
    "assert all([isinstance(field, torch.Tensor) and field.dtype == torch.float64 for field in data[0]]), \"Transition tuples should contain torch tensors whose types are float64\"\n",
    "\n",
    "# print the first transition\n",
    "print(\"Sample transition:\", data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Th1JezEfvir"
   },
   "source": [
    "## Build a dynamics model\n",
    "\n",
    "We now design a model to represent the system dynamics. We choose  a **structured model** inspired from *Linear Time-Invariant (LTI) systems* \n",
    "\n",
    "$$\\dot{x} = f_\\theta(x, u) = A_\\theta(x, u)x + B_\\theta(x, u)u$$\n",
    "\n",
    "where the $(x, u)$ notation for states and actions comes from the Control Theory community and is typically used when they are continuous. Intuitively, we learn at each point $(x_t, u_t)$ the **linearization** of the true dynamics $f$ with respect to $(x, u)$.\n",
    "\n",
    "We parametrize $A_\\theta$ and $B_\\theta$ as two fully-connected networks with one hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F7Gl2kKJfviu",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward initial model on a sample transition: tensor([[-0.2667, -0.0639,  0.1267,  0.0206, -0.0640, -1.1435]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "class DynamicsModel(nn.Module):\n",
    "    STATE_X = 0\n",
    "    STATE_Y = 1\n",
    "\n",
    "    def __init__(self, state_size, action_size, hidden_size, dt):\n",
    "        super().__init__()\n",
    "        self.state_size, self.action_size, self.dt = state_size, action_size, dt\n",
    "        A_size, B_size = state_size * state_size, state_size * action_size\n",
    "        self.A1 = nn.Linear(state_size + action_size, hidden_size)\n",
    "        self.A2 = nn.Linear(hidden_size, A_size)\n",
    "        self.B1 = nn.Linear(state_size + action_size, hidden_size)\n",
    "        self.B2 = nn.Linear(hidden_size, B_size)\n",
    "        \n",
    "        self.A = torch.nn.Sequential(self.A1, torch.nn.ReLU(),  torch.nn.Linear(hidden_size, hidden_size), torch.nn.ReLU(), self.A2)\n",
    "        self.B = torch.nn.Sequential(self.B1, torch.nn.ReLU(),torch.nn.Linear(hidden_size, hidden_size),  torch.nn.ReLU(), self.B2)\n",
    "    def forward(self, x, u):\n",
    "        \"\"\"\n",
    "            QUESTION 2: Predict x_{t+1} = f(x_t, u_t)\n",
    "            \n",
    "            Denoting the state size, action size, and batch size as S, A, N: \n",
    "            \n",
    "            1. Concatenate the states and actions (x,u) to a single tensor.\n",
    "            2. Compute the coefficients A(x,u) and B(x,u) by forwarding the two fully-connected networks with\n",
    "               F.relu activations and linear output. This must be done in one pass for the whole batch of (x,u).\n",
    "            3. Reshape the obtained A and B vectors into a batch of SxS and SxA matrices, S is state size and \n",
    "               A is action size. The resulting tensors should be of shape (N, S, S) and (N, S, A).\n",
    "            4. Compute the batch of state derivatives \\dot{x}, by using the matrix multiplication operator @. \n",
    "               It should be of shape (N, S).\n",
    "            5. Integrate the states dynamics over a timestep dt to obtain the next states x_{t+1}.\n",
    "            6. (Optional) Inductive bias: to accelerate learning, implement the knowledge that the laws of physics\n",
    "               are uniform across space, and hence A(x,u) and B(x,u) cannot depend on the car coordinates (the  \n",
    "               two first component of the state x).\n",
    "            \n",
    "        :param Tensor x: a batch of states, of shape (N, S)\n",
    "        :param Tensor u: a batch of actions, of shape (N, A)\n",
    "        :return a Tensor of predicted next states, of shape (N, S)\n",
    "        \"\"\"\n",
    "        x = x.double()\n",
    "        u = u.double()\n",
    "        xu = torch.cat([x,u], 1).float()\n",
    "        A = self.A(xu).reshape(-1, self.state_size, self.state_size).double()\n",
    "        B = self.B(xu).reshape(-1, self.state_size, self.action_size).double()\n",
    "        \n",
    "        # Bias\n",
    "        #A[:, :, :2] *= 0\n",
    "\n",
    "        dx = (A@x.double().reshape(A.shape[0], -1, 1) + B@u.double().reshape(A.shape[0], -1, 1))\n",
    "\n",
    "        x_next = x + dx.double().squeeze(-1)\n",
    "        #print(x.shape, x_next.shape)\n",
    "        return x_next\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "dynamics = DynamicsModel(state_size=env.observation_space.spaces[\"observation\"].shape[0],\n",
    "                         action_size=env.action_space.shape[0],\n",
    "                         hidden_size=64,\n",
    "                         dt=1/env.unwrapped.config[\"policy_frequency\"])\n",
    "\n",
    "#  Forward a sample transition. \n",
    "#  unqueeze(0) is used to generate a batch of 1 element, by adding a new batch dimension of size 1.\n",
    "state, action = data[0].state.unsqueeze(0), data[0].action.unsqueeze(0)\n",
    "next_state = dynamics(state, action).detach()  # detach() is used here because gradients are unnecessary\n",
    "assert state.shape == next_state.shape\n",
    "assert not torch.equal(next_state, state)\n",
    "print(\"Forward initial model on a sample transition:\", next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FFsgc7gffvi0"
   },
   "source": [
    "## Fit the model on data\n",
    "We can now train our model $f_\\theta$ in a supervised fashion to minimize an MSE loss $L^2(f_\\theta; D)$ over our experience batch $D$ by stochastic gradient descent:\n",
    "\n",
    "$$L^2(f_\\theta; D) = \\frac{1}{|D|}\\sum_{s_t,a_t,s_{t+1}\\in D}||s_{t+1}- f_\\theta(s_t, a_t)||^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwCDLD1wfvi2",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f02dd67bbb74500afcc0dae32465e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train dynamics', max=1500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(dynamics.parameters(), lr=0.02)\n",
    "\n",
    "# Split dataset into training and validation\n",
    "train_ratio = 0.7\n",
    "train_data, validation_data = data[:int(train_ratio * len(data))], \\\n",
    "                              data[int(train_ratio * len(data)):]\n",
    "\n",
    "def compute_loss(model, data_t):\n",
    "    \"\"\"\n",
    "        QUESTION 3: Compute the loss L^2 of the model f_theta on a batch of data D.\n",
    "        \n",
    "        1. You can use either the sum() and **2 operators, or the built-in torch.nn.MSELoss()\n",
    "        \n",
    "    :param model: the dynamics model \n",
    "    :param data_t: a tuple of tensors (states, actions, next_states)\n",
    "    :return: the model loss L^2(f_theta, D)\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    batch_state = data_t[0]\n",
    "    batch_next_state = data_t[2]\n",
    "    batch_action = data_t[1]\n",
    "    \n",
    "    preds = model(batch_state, batch_action)\n",
    "    \n",
    "    loss = torch.mean((preds-batch_next_state)**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def transpose_batch(batch):\n",
    "    return Transition(*map(torch.stack, zip(*batch)))\n",
    "\n",
    "def train(model, train_data, validation_data, epochs=1500):\n",
    "    train_data_t = transpose_batch(train_data)\n",
    "    validation_data_t = transpose_batch(validation_data)\n",
    "    losses = np.full((epochs, 2), np.nan)\n",
    "    for epoch in tnrange(epochs, desc=\"Train dynamics\"):\n",
    "        # Compute loss gradient and step optimizer\n",
    "        loss = compute_loss(model, train_data_t)\n",
    "        validation_loss = compute_loss(model, validation_data_t)\n",
    "        losses[epoch] = [loss.detach().numpy(), validation_loss.detach().numpy()]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Plot losses\n",
    "    plt.plot(losses)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend([\"training\", \"validation\"])\n",
    "    plt.show()\n",
    "\n",
    "train(dynamics, data, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXBODCuYfvi_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize trained dynamics\n",
    "\n",
    "In order to qualitatively evaluate our model, we can choose some values of steering angle *(right, center, left)* and acceleration *(slow, fast)* in order to predict and visualize the corresponding trajectories from an initial state.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 6])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.zeros(6)\n",
    "\n",
    "t.repeat(100,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMPA55bCfvjB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_trajectory(state, actions, model, action_repeat=1):\n",
    "    states = []\n",
    "    for action in actions:\n",
    "        for _ in range(action_repeat):\n",
    "            state = model(state, action)\n",
    "            states.append(state)\n",
    "    return torch.stack(states, dim=0)\n",
    "\n",
    "def predict_batched(state, actions, model):\n",
    "    states = []\n",
    "    for a_batch in actions:\n",
    "        state = model(state.repeat(a_batch.shape[0], 1)[:a_batch.shape[0]], a_batch)\n",
    "        states.append(state)\n",
    "    return torch.stack(states)\n",
    "\n",
    "def plot_trajectory(states, color):\n",
    "    scales = np.array(highway_env.envs.parking_env.ParkingEnv.DEFAULT_CONFIG[\"observation\"][\"scales\"])\n",
    "    states = np.clip(states.squeeze(1).detach().numpy() * scales, -100, 100)\n",
    "    plt.plot(states[:, 0], states[:, 1], color=color, marker='.')\n",
    "    plt.arrow(states[-1,0], states[-1,1], states[-1,4]*1, states[-1,5]*1, color=color)\n",
    "\n",
    "def visualize_trajectories(model, state, horizon=15):\n",
    "    plt.cla()\n",
    "    # Draw a car\n",
    "    plt.plot(state.numpy()[0]+2.5*np.array([-1, -1, 1, 1, -1]),\n",
    "             state.numpy()[1]+1.0*np.array([-1, 1, 1, -1, -1]), 'k')\n",
    "    # Draw trajectories\n",
    "    state = state.unsqueeze(0)\n",
    "    colors = iter(plt.get_cmap(\"tab20\").colors)\n",
    "    # Generate commands\n",
    "    for steering in np.linspace(-0.5, 0.5, 3):\n",
    "        for acceleration in np.linspace(0.8, 0.4, 2):\n",
    "            actions = torch.Tensor([acceleration, steering]).view(1,1,-1)\n",
    "            # Predict trajectories\n",
    "            states = predict_trajectory(state, actions, model, action_repeat=horizon)\n",
    "            plot_trajectory(states, color=next(colors))\n",
    "    plt.axis(\"equal\")\n",
    "    plt.show()\n",
    "    \n",
    "visualize_trajectories(dynamics, state=torch.Tensor([0, 0, 0, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOa0j1_muNXi"
   },
   "source": [
    "Do the predicted trajectories look realistic? If not, you can try to:\n",
    "- Collect more data in $D$\n",
    "- Increase the model capacity (size of hidden layer, number of layers)\n",
    "- Increase the number of training epochs or change the learning rate\n",
    "- Add regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOvpaJ-WRwyA"
   },
   "source": [
    "## Reward model\n",
    "We assume that the reward $R(s,a)$ is known (chosen by the system designer), and takes the form of a **weighted L1-norm** between the state and the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRubRv9buNXj"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected type torch.DoubleTensor but got torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-4713d1fe267f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m print(\"Reward of a sample transition:\", reward_model(torch.Tensor(obs[\"observation\"]).unsqueeze(0),\n\u001b[0;32m---> 38\u001b[0;31m                                                      torch.Tensor(obs[\"desired_goal\"])))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-235-4713d1fe267f>\u001b[0m in \u001b[0;36mreward_model\u001b[0;34m(states, goal, gamma)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgoal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mreward_weigths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREWARD_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgoal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreward_weigths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected type torch.DoubleTensor but got torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "def reward_model(states, goal, gamma=None):\n",
    "    \"\"\"\n",
    "        The reward is a weighted L1-norm between the state and a goal\n",
    "    :param Tensor states: a batch of states. shape: [batch_size, state_size].\n",
    "    :param Tensor goal: a goal state. shape: [state_size].\n",
    "    :param float gamma: a discount factor\n",
    "    \"\"\"\n",
    "    goal = goal.expand(states.shape)\n",
    "    reward_weigths = torch.Tensor(env.unwrapped.REWARD_WEIGHTS)\n",
    "    rewards = -torch.pow(torch.norm((states.double()-goal)*reward_weigths, p=1, dim=-1), 0.5)\n",
    "    if gamma:\n",
    "        time = torch.arange(rewards.shape[0], dtype=torch.float).unsqueeze(-1).expand(rewards.shape)\n",
    "        rewards *= torch.pow(gamma, time)\n",
    "    return rewards\n",
    "\n",
    "def reward_batched(states, goal, H,  gamma=None):\n",
    "    \"\"\"\n",
    "        The reward is a weighted L1-norm between the state and a goal\n",
    "    :param Tensor states: a batch of states. shape: [batch_size, state_size].\n",
    "    :param Tensor goal: a goal state. shape: [state_size].\n",
    "    :param float gamma: a discount factor\n",
    "    \"\"\"\n",
    "    goal = goal.expand(states.shape).double()\n",
    "    states = states.double()\n",
    "    reward_weigths = torch.Tensor(env.unwrapped.REWARD_WEIGHTS)\n",
    "    rewards = -torch.pow(torch.norm((states-goal).reshape(-1, 6)*reward_weigths.double(), p=1, dim=-1), 0.5)\n",
    "    rewards = rewards.reshape(H, -1, 1)\n",
    "    \n",
    "    if gamma:\n",
    "        time = torch.arange(rewards.shape[0], dtype=torch.float).unsqueeze(-1).expand(rewards.shape)\n",
    "        rewards *= torch.pow(gamma, time)\n",
    "    return torch.sum(rewards, 0)\n",
    "\n",
    "\n",
    "\n",
    "obs = env.reset()\n",
    "print(\"Reward of a sample transition:\", reward_model(torch.Tensor(obs[\"observation\"]).unsqueeze(0),\n",
    "                                                     torch.Tensor(obs[\"desired_goal\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5D6W4p7fvjI"
   },
   "source": [
    "## Leverage dynamics model for planning\n",
    "\n",
    "We now use the learnt dynamics model $f_\\theta$ for planning.\n",
    "In order to solve the optimal control problem, we use a sampling-based optimization algorithm: the **Cross-Entropy Method** (`CEM`). It is an optimization algorithm applicable to problems that are both **combinatorial** and **continuous**, which is our case: find the best performing sequence of actions.\n",
    "\n",
    "This method approximates the optimal importance sampling estimator by repeating two phases:\n",
    "1. **Draw samples** from a probability distribution. We use Gaussian distributions over sequences of actions.\n",
    "2. Minimize the **cross-entropy** between this distribution and a **target distribution** to produce a better sample in the next iteration. We define this target distribution by selecting the top-k performing sampled sequences.\n",
    "\n",
    "![Credits to Olivier Sigaud](https://github.com/yfletberliac/rlss2019-hands-on/blob/master/imgs/cem.png?raw=1)\n",
    "\n",
    "Note that as we have a local linear dynamics model, we could instead choose an `Iterative LQR` planner which would be more efficient. We prefer `CEM` in this educational setting for its simplicity and generality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzPKYg23fvjL",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned action: tensor([ 0.9500, -0.2679])\n"
     ]
    }
   ],
   "source": [
    "def cem_planner(state, goal, action_size, model, horizon=3, population=100, selection=10, iterations=5):\n",
    "    \"\"\"\n",
    "        QUESTION 4: Planning with the Cross-Entropy Method\n",
    "        \n",
    "        Denoting the horizon, population size, selection size, state size and action size as H, P, K, S, A:\n",
    "        \n",
    "        1. Initialize the distribution of actions (a_1, ..., a_H) to a standard normal N(0,1), by setting their\n",
    "           mean mu and standard deviations sigma, each of shape (H, 1, A).\n",
    "        2. (Loop over iterations).\n",
    "        3. Sample a population of P sequences of actions from the parametrized normal distribution. \n",
    "           You can use torch.randn(shape) to generate a tensor of normally distributed values in N(0,1).\n",
    "           The sampled actions should belong the the action space boundaries (-1, 1).\n",
    "           These sequences should be stored in a tensor of shape (H, P, A).\n",
    "        4. Predict the corresponding trajectories starting from the current state, and store them in a tensor\n",
    "           of shape (H, P, S). The predict_trajectory() method defined above can be used.\n",
    "        5. Compute the rewards along the trajectories using the reward_model(), and the corresponding trajectory\n",
    "           returns by summing over the horizon.\n",
    "        6. Find the K best returns by using the torch.topk() method.\n",
    "        7. Update the distribution parameters to fit the selected actions.  You can use torch.mean() and\n",
    "           torch.std().\n",
    "        8. (After loop completion) return the first mean action.\n",
    "        \n",
    "    :param Tensor state: the current state, of shape (S,)\n",
    "    :param Tensor goal: the desired goal, of shape (S,)\n",
    "    :param int action_size: the size A of the action space\n",
    "    :param int horizon: the planning horizon H, i.e. the number of timesteps\n",
    "    :param int population: the number P of predicted trajectories\n",
    "    :param int selection: the number K of best trajectories selected to fit a new distribution\n",
    "    :param int iterations: the number of iterations\n",
    "    :return: the recommended action, of shape (A,)\n",
    "    \"\"\"\n",
    "    mu = torch.zeros((horizon, 1, action_size))\n",
    "    sigma = torch.ones((horizon, 1, action_size))\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        population_list = []\n",
    "        for i_pop in range(population):\n",
    "            acts = torch.randn((horizon, 1, action_size))*sigma + mu\n",
    "            acts = torch.clamp(acts, -1, 1)\n",
    "            population_list.append(acts)\n",
    "        \n",
    "        actions = torch.cat(population_list, 1)\n",
    "        trajectories = predict_batched(state=state, actions=actions, model=model)\n",
    "        rewards = reward_batched(states=trajectories, goal=goal, H=horizon)\n",
    "        \n",
    "        # take elite\n",
    "        vals, idxs = torch.topk(rewards.flatten(), k=selection)\n",
    "        elite_actions = actions[:, idxs]\n",
    "        \n",
    "        # fit dist \n",
    "        mu = torch.mean(elite_actions, 1)\n",
    "        sigma = torch.std(elite_actions, 1)\n",
    "        \n",
    "    return mu[0]\n",
    "        \n",
    "    \n",
    "  \n",
    "# Run the planner on a sample transition\n",
    "action = cem_planner(torch.Tensor(obs[\"observation\"]),\n",
    "                     torch.Tensor(obs[\"desired_goal\"]),\n",
    "                     env.action_space.shape[0],\n",
    "                     model=dynamics)\n",
    "assert env.action_space.contains(action.numpy())\n",
    "print(\"Planned action:\", action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8L6vEPWyea7"
   },
   "source": [
    "## Visualize a few episodes\n",
    "\n",
    "En voiture, Simone !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xOcOP7Of18T2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250926b690d1477ca2aa7615c5ee6697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test episodes', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'show_videos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-7fcc51a2424a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mshow_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_videos' is not defined"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"parking-v0\")\n",
    "env = Monitor(env, './video', force=True, video_callable=lambda episode: False)\n",
    "all_eps = []\n",
    "for episode in tnrange(3, desc=\"Test episodes\"):\n",
    "    obs, done = env.reset(), False\n",
    "    ep_rewards = []\n",
    "    while not done:\n",
    "        action = cem_planner(torch.Tensor(obs[\"observation\"]),\n",
    "                             torch.Tensor(obs[\"desired_goal\"]),\n",
    "                             env.action_space.shape[0], model=dynamics, population=100)\n",
    "        obs, reward, done, info = env.step(action.numpy())\n",
    "        ep_rewards.append(reward)\n",
    "    all_eps.append(ep_rewards)\n",
    "    \n",
    "env.close()\n",
    "show_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12c3a09e8>]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards = np.asarray(all_eps)\n",
    "plt.plot(rewards[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psBBQIv4fvjT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Is the performance satisfying? \n",
    "If not, try to identify if the problem lies with the dynamics model or the planner.\n",
    "If you think that the planner is at fault, you can try to:\n",
    "- Increase the size of the population.\n",
    "- Increase the planning horizon.\n",
    "- Add action repeat in the planning procedure, in order to increase the effective planning horizon without increasing\n",
    "  the size of the optimization space (sampled sequences of actions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1agvYMDyRwyf"
   },
   "source": [
    "## Limits\n",
    "\n",
    "### Model bias\n",
    "\n",
    "In model-based reinforcement learning, we replace our original optimal control problem by another problem: optimizing our learnt approximate MDP. When settling for this approximate MDP to plan with, we introduce a **bias** that can only **decrease the true performance** of the corresponding planned policy. This is called the problem of model bias.\n",
    "\n",
    "In some MDPs, even slight model errors lead to a dramatic drop in performance, as illustrated in the beginning of the following video:\n",
    "\n",
    "[![Approximate Robust Control of Uncertain Dynamical Systems](https://img.youtube.com/vi/8khqd3BJo0A/0.jpg)](https://www.youtube.com/watch?v=8khqd3BJo0A)\n",
    "\n",
    "The question of how to address model bias belongs to the field of **Safe Reinforcement Learning**. \n",
    "\n",
    "### [L'appel du vide](https://www.urbandictionary.com/define.php?term=L%27appel%20du%20vide)\n",
    "\n",
    "The model will be accurate only on some region of the state space that was explored and covered in $D$.\n",
    "Outside of $D$, the model may diverge and **hallucinate** important rewards.\n",
    "This effect is problematic when the model is used by a planning algorithm, as the latter will try to **exploit** these hallucinated high rewards and will steer the agent towards **unknown** (and thus dangerous) **regions** where the model is erroneously optimistic.\n",
    "\n",
    "### Computational cost of planning\n",
    "\n",
    "At test time, the planning step typically requires **sampling a lot of trajectories** to find a near-optimal candidate, wich may turn out to be very costly. This may be prohibitive in a high-frequency real-time setting. The **model-free** methods which directly recommend the best action are **much more efficient** in that regard."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03.ModelBased.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
