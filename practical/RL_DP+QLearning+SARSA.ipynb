{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "79lhHm24U7xN"
   },
   "source": [
    "##### Run this cell to set your notebook up (only mandatory if rlss2019-docker image is not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIZVE9LNU7xR"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/yfletberliac/rlss2019-hands-on.git > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yaW9kB9aU7xY"
   },
   "source": [
    "# Reinforcement Learning - Practical Session 1\n",
    "\n",
    "\n",
    "## Review\n",
    "\n",
    "A Markov Decision Process (MDP) is defined as tuple $(S, A, P, r, \\gamma)$ where:\n",
    "* $S$ is the state space\n",
    "* $A$ is the action space \n",
    "* $P$ represents the transition probabilities, $P(s,a,s')$ is the probability of arriving at state $s'$ by taking action $a$ in state $s$\n",
    "* $r$ is the reward function such that $r(s,a,s')$ is the reward obtained by taking action $a$ in state $s$ and arriving at $s'$\n",
    "* $\\gamma$ is the discount factor\n",
    "\n",
    "A deterministic policy $\\pi$ is a mapping from $S$ to $A$: $\\pi(s)$ is the action to be taken at state $s$.\n",
    "\n",
    "The goal of an agent is to find the policy $\\pi$ that maximizes the expected sum of discounted rewards by following $\\pi$. The value of $\\pi$ is defined as\n",
    "\n",
    "$$\n",
    "V_\\pi(s) = E\\left[ \\sum_{t=0}^\\infty \\gamma^t r(S_t, A_t, S_{t+1}) | S_0 = s \\right]\n",
    "$$\n",
    "\n",
    "$V_\\pi(s)$ and the optimal value function, defined as $V^*(s) = \\max_\\pi V_\\pi(s)$, can be shown to satisfy the Bellman equations:\n",
    "\n",
    "$$\n",
    "V_\\pi(s) = \\sum_{s' \\in S}  P(s,\\pi(s),s')[r(s,\\pi(s),s') + \\gamma V_\\pi(s')]\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "V^*(s) = \\max_{a\\in A} \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma V^*(s')]\n",
    "$$\n",
    "\n",
    "It is sometimes better to work with Q functions:\n",
    "\n",
    "$$\n",
    "Q_\\pi(s, a) = \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma  Q_\\pi(s', \\pi(s')]\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "Q^*(s, a) = \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma \\max_{a'} Q^*(s', a')]\n",
    "$$\n",
    "\n",
    "such that $V_\\pi(s) = Q_\\pi(s, \\pi(s))$ and $V^*(s) = \\max_a Q^*(s, a)$.\n",
    "\n",
    "\n",
    "### Using value iteration to compute an optimal policy\n",
    "If the reward function and the transition probabilities are known (and the state and action spaces are not very large), we can use dynamic programming methods to compute $V^*(s)$. Value iteration is one way to do that.\n",
    "\n",
    "\n",
    "#####  Value iteration to compute $V^*(s)$\n",
    "$$\n",
    "T^* Q(s,a) = \\sum_{s'}P(s'|s,a)[ r(s, a, s') + \\gamma \\max_{a'} Q(s', a')]   \\\\\n",
    "$$\n",
    "\n",
    "\n",
    "* For any $Q_0$, let $Q_n = T^* Q_{n-1}$. \n",
    "* We have $\\lim_{n\\to\\infty}Q_n = Q^*$ and $Q^* = T^* Q^*$\n",
    "\n",
    "\n",
    "##### Finding the optimal policy from $V^\\pi(s)$\n",
    "\n",
    "The optimal policy $\\pi^*$ can be computed as\n",
    "\n",
    "$$\n",
    "\\pi^*(s) \\in \\arg\\max_{a\\in A} Q^*(s, a) =  \\arg\\max_{a\\in A} \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma V^*(s')]\n",
    "$$\n",
    "\n",
    "###  Q-Learning and SARSA \n",
    "\n",
    "When the reward function and the transition probabilities are *unknown*, we cannot use dynamic programming to find the optimal value function. Q-Learning and SARSA are stochastic approximation algorithms that allow us to estimate the value function by using only samples from the environment.\n",
    "\n",
    "#####  Q-learning\n",
    "\n",
    "The Q-Learning algorithm allows us to estimate the optimal Q function using only trajectories from the MDP obtained by following some exploration policy. \n",
    "\n",
    "Q-learning with $\\varepsilon$-greedy exploration does the following update at time $t$:\n",
    "\n",
    "1. In state $s_t$, take action $a_t$  such that $a_t$ is random with probability $\\varepsilon$ and $a_t \\in \\arg\\max_a \\hat{Q}_t(s_t,a) $ with probability $1-\\varepsilon$;\n",
    "2. Observe $s_{t+1}$ and reward $r_t$;\n",
    "3. Compute $\\delta_t = r_t + \\gamma \\max_a \\hat{Q}_t(s_{t+1}, a) - \\hat{Q}_t(s_t, a_t)$;\n",
    "4. Update $\\hat{Q}_{t+1}(s, a) = \\hat{Q}_t(s, a) + \\alpha_t(s,a)\\delta_t\\mathbb{1}\\{s=s_t, a=a_t\\}  $\n",
    "\n",
    "\n",
    "##### SARSA\n",
    "\n",
    "SARSA is similar to Q-learning, but it is an *on-policy* algorithm: it follows a (stochastic) policy $\\pi_Q$ and updates its estimate towards the value of this policy. One possible choice is:\n",
    "\n",
    "$$\n",
    "\\pi_Q(a|s) = \\frac{ \\exp(\\tau^{-1}Q(s,a))  }{\\sum_{a'}\\exp(\\tau^{-1}Q(s,a')) }\n",
    "$$\n",
    "where $\\tau$ is a \"temperature\" parameter: when $\\tau$ approaches 0, $\\pi_Q(a|s)$ approaches the greedy (deterministic) policy $a \\in \\arg\\max_{a'}Q(s,a')$.\n",
    "\n",
    "At each time $t$, SARSA keeps an estimate $\\hat{Q}_t$ of the true Q function and uses $\\pi_{\\hat{Q}_t}(a|s)$ to choose the action $a_t$. If $\\tau \\to 0$ with a proper rate as $t \\to \\infty$, $\\hat{Q}_t$ converges to $Q$ and $\\pi_{\\hat{Q}_t}(a|s)$ converges to the optimal policy $\\pi^*$. \n",
    "\n",
    "The SARSA update at time $t$ is done as follows:\n",
    "\n",
    "1. In state $s_t$, take action $a_t \\sim \\pi_{\\hat{Q}_t}(a|s_t)$ ;\n",
    "2. Observe $s_{t+1}$ and reward $r_t$;\n",
    "3. Sample the next action $a_{t+1} \\sim \\pi_{\\hat{Q}_t}(a|s_{t+1})$;\n",
    "4. Compute $\\delta_t = r_t + \\gamma \\hat{Q}_t(s_{t+1}, a_{t+1}) - \\hat{Q}_t(s_t, a_t)$\n",
    "5. Update $\\hat{Q}_{t+1}(s, a) = \\hat{Q}_t(s, a) + \\alpha_t(s,a)\\delta_t\\mathbb{1}\\{s=s_t, a=a_t\\}$\n",
    "\n",
    "## Goals\n",
    "\n",
    "Your goal is to implement Value Iteration, Q-Learning and SARSA for the [Frozen Lake](https://gym.openai.com/envs/FrozenLake-v0/) environment.\n",
    "\n",
    "* In exercise 1, you will implement the Bellman operator $T^*$ and verify its contraction property.\n",
    "* In exercise 2, you will implement value iteration.\n",
    "* In exercises 3 and 4, you will implement Q-Learning and SARSA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-N1Ylj1HU7xf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './rlss2019-hands-on/utils')\n",
    "# If using the Docker image, replace by:\n",
    "# sys.path.insert(0, '../utils')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax # for SARSA\n",
    "import matplotlib.pyplot as plt\n",
    "from frozen_lake import FrozenLake\n",
    "from test_env import ToyEnv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntNltx-_U7xj"
   },
   "source": [
    "# FrozenLake environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qrQYUP1yU7xk"
   },
   "source": [
    "(You can use ToyEnv1 to debug your algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMmF3I8cU7xl",
    "outputId": "8f99db16-0344-41c1-f7d0-67b217000071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of states: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Set of actions: [0, 1, 2, 3]\n",
      "Number of states:  16\n",
      "Number of actions:  4\n",
      "P has shape:  (16, 4, 16)\n",
      "discount factor:  0.95\n",
      "\n",
      "initial state:  0\n",
      "reward at (s=1, a=3,s'=2):  0.0\n",
      "\n",
      "random policy =  [1 0 0 0 3 0 1 1 0 0 3 0 0 0 1 1]\n",
      "(s, a, s', r):\n",
      "0 1 4 0.0\n",
      "4 3 0 0.0\n",
      "0 1 4 0.0\n",
      "4 3 0 0.0\n",
      "\n",
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 0\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of FrozenLake\n",
    "# --- If deterministic=False, transitions are stochastic. Try both cases!\n",
    "env = FrozenLake(gamma=0.95, deterministic=True, data_path=\"./rlss2019-hands-on/data\") \n",
    "\n",
    "# Small environment for debugging\n",
    "#env = ToyEnv1(gamma=0.95)\n",
    "\n",
    "# Useful attributes\n",
    "print(\"Set of states:\", env.states)\n",
    "print(\"Set of actions:\", env.actions)\n",
    "print(\"Number of states: \", env.Ns)\n",
    "print(\"Number of actions: \", env.Na)\n",
    "print(\"P has shape: \", env.P.shape)  # P[s, a, s'] = env.P[s, a, s']\n",
    "print(\"discount factor: \", env.gamma)\n",
    "print(\"\")\n",
    "\n",
    "# Usefult methods\n",
    "state = env.reset() # get initial state\n",
    "print(\"initial state: \", state)\n",
    "print(\"reward at (s=1, a=3,s'=2): \", env.reward_func(1,3,2))\n",
    "print(\"\")\n",
    "\n",
    "# A random policy\n",
    "policy = np.random.randint(env.Na, size = (env.Ns,))\n",
    "print(\"random policy = \", policy)\n",
    "\n",
    "# Interacting with the environment\n",
    "print(\"(s, a, s', r):\")\n",
    "for time in range(4):\n",
    "    action = policy[state]\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    print(state, action, next_state, reward)\n",
    "    if done:\n",
    "        break\n",
    "    state = next_state\n",
    "print(\"\")\n",
    "\n",
    "# Visualizing the environment\n",
    "try:\n",
    "    env.render()\n",
    "except:\n",
    "    pass # render not available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fO072knpU7xr"
   },
   "source": [
    "# Exercise 1: Bellman operator\n",
    "\n",
    "1. Write a function that takes an environment and a state-action value function $Q$ as input and returns the Bellman optimality operator applied to $Q$, $T^* Q$ and the greedy policy with respect to $Q$.\n",
    "3. Let $Q_1$ and $Q_2$ be state-action value functions. Verify the contraction property:  $\\Vert T^* Q_1 - T^* Q_2\\Vert \\leq \\gamma ||Q_1 - Q_2||$, where $||Q|| = \\max_{s,a} |Q(s,a)|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZMfziJoU7xs"
   },
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Your answer to 1.\n",
    "# --------------\n",
    "def bellman_operator(Q, env):\n",
    "    TQ = np.zeros_like(Q)\n",
    "    greedy_policy = [np.argmax(Q[s]) for s in range(env.Ns)]\n",
    "    for s1 in range(env.Ns): \n",
    "        for a in range(env.Na):\n",
    "            for s2 in range(env.Ns):\n",
    "                TQ[s1, a] += env.P[s1, a, s2]*(env.reward_func(s1, a, s2) + env.gamma*Q[s2, greedy_policy[s2]])\n",
    "\n",
    "            \n",
    "    greedy_policy = [np.argmax(TQ[s]) for s in range(env.Ns)]\n",
    "    return TQ, greedy_policy\n",
    "\n",
    "\n",
    "# def bellman_operator(Q, env):\n",
    "#     TQ = Q.copy()\n",
    "#     greedy_policy = [np.argmax(Q[s]) for s in range(env.Ns)]\n",
    "#     s1 = env.state\n",
    "#     a = greedy_policy[env.state]\n",
    "#     s2, r, _, _ = env.step(a)\n",
    "#     TQ = r + env.gamma*Q[s2,greedy_policy[s2]]    \n",
    "            \n",
    "#     greedy_policy = [np.argmax(Q[s]) for s in range(env.Ns)]\n",
    "#     return TQ, greedy_policy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.random.rand(env.Ns, env.Na)\n",
    "Q, gp = bellman_operator(Q, env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jlcIqWFU7xv",
    "outputId": "3a1447ef-b0ea-4330-f38f-f7cb0b39fc70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contraction of Bellman operator\n",
      "0.0006399448731998526 <= 0.9616264142391017\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Your answer to 2.\n",
    "# --------------\n",
    "print(\"Contraction of Bellman operator\")\n",
    "\n",
    "Q1 = np.asarray(np.random.rand(env.Ns, env.Na))\n",
    "Q2 = np.asarray(np.random.rand(env.Ns, env.Na))\n",
    "\n",
    "TQ1 = Q1.copy()\n",
    "TQ2 = Q2.copy()\n",
    "for i in range(100):\n",
    "    TQ1, _ = bellman_operator(TQ1, env)\n",
    "    TQ2, _ = bellman_operator(TQ2, env)\n",
    "\n",
    "    \n",
    "    \n",
    "print(np.max(np.abs(TQ1-TQ2)), \"<=\", np.max(np.abs(Q1-Q2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGRmnPrYU7xz"
   },
   "source": [
    "# Exercise 2: Value iteration\n",
    "\n",
    "1. (Optimal Value function) Write a function that takes as input an initial state-action value function `Q0` and an environment `env` and returns a vector `Q` such that $||T^* Q -  Q ||_\\infty \\leq \\varepsilon $ and the greedy policy with respect to $Q$.\n",
    "2. Test the convergence of the function you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzbWj0K_U7x1"
   },
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Your answer to 1.\n",
    "# --------------\n",
    "def value_iteration(Q0, env, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Finding the optimal value function. To be done!\n",
    "    \"\"\"\n",
    "    Q = Q0.copy()\n",
    "    while True:\n",
    "        TQ, policy = bellman_operator(Q, env)\n",
    "        if np.max(np.abs(TQ-Q)) <= epsilon:\n",
    "            break\n",
    "        Q = TQ\n",
    "    return Q, policy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKqpwR10U7x3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.47018179e+01, 1.54755988e+01, 1.54755988e+01, 1.47018179e+01],\n",
       "        [1.47018179e+01, 9.89072290e-07, 1.62901051e+01, 1.54755988e+01],\n",
       "        [1.54755988e+01, 1.71474801e+01, 1.54755988e+01, 1.62901051e+01],\n",
       "        [1.62901051e+01, 9.83627752e-07, 1.54755988e+01, 1.54755988e+01],\n",
       "        [1.54755988e+01, 1.62901051e+01, 9.89072290e-07, 1.47018179e+01],\n",
       "        [9.89072290e-07, 9.89072290e-07, 9.89072290e-07, 9.89072290e-07],\n",
       "        [9.89072290e-07, 1.80499801e+01, 9.83627752e-07, 1.62901051e+01],\n",
       "        [9.83627752e-07, 9.83627752e-07, 9.83627752e-07, 9.83627752e-07],\n",
       "        [1.62901051e+01, 9.63337100e-07, 1.71474801e+01, 1.54755988e+01],\n",
       "        [1.62901051e+01, 1.80499801e+01, 1.80499801e+01, 9.89072290e-07],\n",
       "        [1.71474801e+01, 1.89999801e+01, 8.98357643e-07, 1.71474801e+01],\n",
       "        [8.98357643e-07, 8.98357643e-07, 8.98357643e-07, 8.98357643e-07],\n",
       "        [9.63337100e-07, 9.63337100e-07, 9.63337100e-07, 9.63337100e-07],\n",
       "        [9.63337100e-07, 1.80499801e+01, 1.89999801e+01, 1.71474801e+01],\n",
       "        [1.80499801e+01, 1.89999801e+01, 1.99999801e+01, 1.80499801e+01],\n",
       "        [1.99999801e+01, 1.99999801e+01, 1.99999801e+01, 1.99999801e+01]]),\n",
       " [1, 2, 1, 0, 1, 0, 1, 0, 2, 1, 1, 0, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Q0 = np.asarray(np.random.rand(env.Ns, env.Na))\n",
    "value_iteration(Q0, env, epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGYXRZrwU7x6"
   },
   "source": [
    "# Exercise 3: Q-Learning\n",
    "\n",
    "#####  Q-learning\n",
    "\n",
    "The Q-Learning algorithm allows us to estimate the optimal Q function using only trajectories from the MDP obtained by following some exploration policy. \n",
    "\n",
    "Q-learning with $\\varepsilon$-greedy exploration does the following update at time $t$:\n",
    "\n",
    "1. In state $s_t$, take action $a_t$  such that $a_t$ is random with probability $\\varepsilon$ and $a_t \\in \\arg\\max_a \\hat{Q}_t(s_t,a) $ with probability $1-\\varepsilon$ (**act function**);\n",
    "2. Observe $s_{t+1}$ and reward $r_t$ (**step in the environment**);\n",
    "3. Compute $\\delta_t = r_t + \\gamma \\max_a \\hat{Q}_t(s_{t+1}, a) - \\hat{Q}_t(s_t, a_t)$ (**to be done in .optimize()**) ;\n",
    "4. Update $\\hat{Q}_{t+1}(s, a) = \\hat{Q}_t(s, a) + \\alpha_t(s,a)\\delta_t\\mathbb{1}\\{s=s_t, a=a_t\\}$ (**in optimize too**)\n",
    "\n",
    "\n",
    "Implement Q-learning and test its convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zepYms2U7x7"
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# Q-Learning implementation\n",
    "# ------------------------------\n",
    "\n",
    "class QLearning:\n",
    "    \"\"\"\n",
    "    Implements Q-learning algorithm with epsilon-greedy exploration\n",
    "    \"\"\"\n",
    "    def __init__(self, env, gamma, lr, epsilon): # You can add more argument to your init (lr decay, eps decay)\n",
    "        self.Q = np.ones((env.Ns, env.Na))/5.0\n",
    "        self.visitation = np.zeros(self.Q.shape[0])\n",
    "        self.epsilon = epsilon\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.env = env\n",
    "        self.t = 1\n",
    "    \n",
    "    def act(self, state, greedy=False): # You don't have to use this template for your algorithm, those are just hints\n",
    "        \"\"\"\n",
    "        Takes a state as input and outputs an action (acting greedily or not with respect to the q function)\n",
    "        \"\"\"\n",
    "        if greedy or np.random.rand(1) > self.epsilon:\n",
    "            return np.argmax(self.Q[state])\n",
    "        else:\n",
    "            return np.random.randint(self.Q.shape[1])\n",
    "        self.visitation[state]+=1\n",
    "    \n",
    "    def optimize(self, state, action, next_state, reward):\n",
    "        \"\"\"\n",
    "        Takes (s, a, s', r) as input and optimize the Q function\n",
    "        \"\"\"\n",
    "        self.Q[state, action] += (reward + self.gamma*np.max(self.Q[next_state]) - self.Q[state,action])*self.lr\n",
    "        self.t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = QLearning(env, env.gamma, 5e-3, 1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ie9t3NnKU7x-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.933763786610143e-05\n",
      "Q policy: [1, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0]\n",
      "Optimal policy: [1, 2, 1, 0, 1, 0, 1, 0, 2, 1, 1, 0, 0, 2, 2, 0]\n",
      "Diff: [0 0 0 0 0 0 0 1 0 0 0 1 2 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Convergence of Q-Learning\n",
    "# ---------------------------\n",
    "\n",
    "# Number of Q learning iterations\n",
    "n_steps = int(1e5)  \n",
    "#n_steps = 10\n",
    "\n",
    "Q0 = np.ones((env.Ns, env.Na))\n",
    "# You can use Q_opt from value iteration to check the correctness of q learning\n",
    "Q_opt, pi_opt = value_iteration(Q0, env, epsilon=1e-6)\n",
    "#       ^ and the optimal policy too\n",
    "\n",
    "reward = []\n",
    "algo.lr = 1\n",
    "for e in range(1000):\n",
    "    s = env.reset()\n",
    "    ep_reward = []\n",
    "    for i in range(20):\n",
    "        a = algo.act(s)\n",
    "        s2, r, _, d  = env.step(a)\n",
    "        algo.optimize(s, a, s2, r)\n",
    "        if d:\n",
    "            break\n",
    "        s = s2\n",
    "        ep_reward.append(r)\n",
    "    reward.append(ep_reward)\n",
    "\n",
    "reward = np.asarray(reward)\n",
    "print(np.max(np.abs(Q_opt-algo.Q)))\n",
    "\n",
    "print(\"Q policy:\", [np.argmax(algo.Q[s]) for s in range(env.Ns)])\n",
    "print(\"Optimal policy:\",  pi_opt)\n",
    "print(\"Diff:\", np.asarray([np.argmax(algo.Q[s]) for s in range(env.Ns)])-pi_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 4\n"
     ]
    }
   ],
   "source": [
    "a = algo.act(s)\n",
    "s2, r, _, d  = env.step(a)\n",
    "env.render()\n",
    "s = s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.47018185e+01, 1.54755994e+01, 1.54755994e+01, 1.47018185e+01],\n",
       "       [1.47018185e+01, 1.01777042e-06, 1.62901057e+01, 1.54755994e+01],\n",
       "       [1.54755994e+01, 1.71474807e+01, 1.54755994e+01, 1.62901057e+01],\n",
       "       [1.62901057e+01, 1.01777042e-06, 1.54755994e+01, 1.54755994e+01],\n",
       "       [1.54755994e+01, 1.62901057e+01, 1.01777042e-06, 1.47018185e+01],\n",
       "       [1.01777042e-06, 1.01777042e-06, 1.01777042e-06, 1.01777042e-06],\n",
       "       [1.01777042e-06, 1.80499807e+01, 1.01777042e-06, 1.62901057e+01],\n",
       "       [1.01777042e-06, 1.01777042e-06, 1.01777042e-06, 1.01777042e-06],\n",
       "       [1.62901057e+01, 1.01777042e-06, 1.71474807e+01, 1.54755994e+01],\n",
       "       [1.62901057e+01, 1.80499807e+01, 1.80499807e+01, 1.01777042e-06],\n",
       "       [1.71474807e+01, 1.89999807e+01, 1.01777042e-06, 1.71474807e+01],\n",
       "       [1.01777042e-06, 1.01777042e-06, 1.01777042e-06, 1.01777042e-06],\n",
       "       [1.01777042e-06, 1.01777042e-06, 1.01777042e-06, 1.01777042e-06],\n",
       "       [1.01777042e-06, 1.80499807e+01, 1.89999807e+01, 1.71474807e+01],\n",
       "       [1.80499807e+01, 1.89999807e+01, 1.99999807e+01, 1.80499807e+01],\n",
       "       [1.99999807e+01, 1.99999807e+01, 1.99999807e+01, 1.99999807e+01]])"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1191f6b70>"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Q_opt)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1193197f0>"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(algo.Q)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x11944bc50>"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(algo.Q-Q_opt)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 20)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1176e69b0>]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sum(reward, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x118030ba8>]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEDlJREFUeJzt3X2MZXV9x/H3R5YHeQi7dEdEoN3VUBK0WuikSm2s9YkVibRN/4BoA0qzSW2tWhMCkviQ/tH6kFaNRtwoSluKWsSHEK1SqtEmFjvL4/IkCIhs0R001camUeK3f9yzMDvuPN175s69v75fyc2c8zvn3vOd39z5zJnfOfecVBWSpOn3pI0uQJLUDwNdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1IhN49zY1q1ba9u2bePcpCRNvd27dz9aVTMrrTfWQN+2bRtzc3Pj3KQkTb0k31nNeg65SFIjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiLGehz6sz968lzd+8paNLkOShnb9m17AKccfs67bmIo9dMNc0rS79Nrb130bUxHokjTtHvnR/677Ngx0SWqEgS5JY5Cs/zYMdElqhIEuSY0w0CVpDBxykaRGhPVPdANdksbAPXRJakTV+m9jxUBPckWSfUn2HGTZm5NUkq3rU54kabVWs4f+cWDH4sYkJwMvAx7quSZJas5EDLlU1deAHx5k0d8CFwNj+EdCkqbbGPJ8uDH0JOcCe6vq1lWsuzPJXJK5+fn5YTYnSVqFNQd6kiOBtwBvXc36VbWrqmaranZmZmatm5MkrdIwe+jPALYDtyZ5EDgJuCnJU/ssTJJakjEMoq/5BhdVdTvwlP3zXajPVtWjPdYlSU2ZiDH0JFcD3wBOTfJwkovWvyxJass4zh5ZcQ+9qs5fYfm23qqRJA3NT4pK0hhMxJCLJKkHk/DBIknS6NxDlyStmoEuSY0w0CVpDMbxwSIDXZLGwDF0SWrE9q1Hrfs2piLQ97zjrI0uQZJG8gdnnLTu25iKQD/68DVfckaSJspE3OBCkjQ6x9AlSatmoEvSGHjaoiQ1wiEXSdKqGeiSNAae5SJJjagx3LJoNbeguyLJviR7FrS9O8ndSW5L8pkkm9e3TEmabpOyh/5xYMeituuBZ1XVs4FvAZf2XJckNWUiAr2qvgb8cFHbl6vqsW7234H1/0yrJGlZfYyhvxb4Yg+vI0nNyhhOXBwp0JNcBjwGXLXMOjuTzCWZm5+fH2VzkqRlDB3oSS4EzgFeVbX08duq2lVVs1U1OzMzM+zmJGm6jWEMfajLGCbZAVwM/E5V/U+/JUmShrGa0xavBr4BnJrk4SQXAR8AjgGuT3JLksvXuU5Jmmrj+Oj/invoVXX+QZo/ug61SJJG4CdFJakRBrokjYGXz5UkrZqBLklj4PXQJakRE3EtF0nSdDDQJWkMJv5aLpKkyWGgS9IYPPvkY9d9Gwa6JI3BkzwPXZLa4GmLkqRVM9AlqREGuiQ1wkCXpEYY6JLUCANdksZgIq7lkuSKJPuS7FnQdlyS65Pc233dsr5lSpJWspo99I8DOxa1XQLcUFWnADd085KkDbRioFfV14AfLmo+F7iym74S+L2e65IkrdGwY+jHV9Uj3fT3gON7qkeSNKSRD4pWVQG11PIkO5PMJZmbn58fdXOSpCUMG+jfT3ICQPd131IrVtWuqpqtqtmZmZkhNydJ022Sr4f+eeCCbvoC4HP9lCNJGtZqTlu8GvgGcGqSh5NcBPw18NIk9wIv6eYlSRto00orVNX5Syx6cc+1SJJG4CdFJakRBrokNcJAl6QxmIhruUiSpoOBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokjYHXcpEkrZqBLkmNMNAlqREjBXqSNyW5I8meJFcnOaKvwiRJazN0oCc5EfhzYLaqngUcApzXV2GSpLUZdchlE/DkJJuAI4H/HL0kSWpPWP/TXIYO9KraC7wHeAh4BPhRVX158XpJdiaZSzI3Pz8/fKWSpGWNMuSyBTgX2A48DTgqyasXr1dVu6pqtqpmZ2Zmhq9UkrSsUYZcXgI8UFXzVfUz4Frgt/opS5K0VqME+kPA85IcmSTAi4G7+ilLkrRWo4yh3whcA9wE3N691q6e6pIkrdGmUZ5cVW8D3tZTLZLULK/lIklaNQNdkhphoEtSIwx0SWqEgS5JjTDQJWkMxnCSi4EuSa0w0CWpEQa6JDXCQJekRhjoktQIA12SxiBjuJiLgS5JjTDQJakRBrokNcJAl6RGGOiS1IiRAj3J5iTXJLk7yV1JzuyrMElqyTiu5TLSLeiA9wH/XFV/mOQw4MgeapIkDWHoQE9yLPAC4EKAqvop8NN+ypIkrdUoQy7bgXngY0luTvKRJEf1VJckaY1GCfRNwBnAh6rqdOAnwCWLV0qyM8lckrn5+fkRNidJWs4ogf4w8HBV3djNX8Mg4A9QVbuqaraqZmdmZkbYnCRpOUMHelV9D/huklO7phcDd/ZSlSQ1ZgyXchn5LJfXA1d1Z7jcD7xm9JIkScMYKdCr6hZgtqdaJEkj8JOiktQIA12SGmGgS1IjDHRJGgPvWCRJWjUDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREjB3qSQ5LcnOS6PgqSJA2njz30NwB39fA6kqQRjBToSU4CXgF8pJ9yJEnDGnUP/b3AxcDPl1ohyc4kc0nm5ufnR9ycJGkpQwd6knOAfVW1e7n1qmpXVc1W1ezMzMywm5MkrWCUPfTnA69M8iDwCeBFSf6hl6okSWs2dKBX1aVVdVJVbQPOA/61ql7dW2WSpDXxPHRJasSmPl6kqr4KfLWP15IkDcc9dElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWrE0IGe5OQkX0lyZ5I7kryhz8IkSWszyi3oHgPeXFU3JTkG2J3k+qq6s6faJElrMPQeelU9UlU3ddP/DdwFnNhXYZKktellDD3JNuB04MY+Xk+StHYjB3qSo4FPA2+sqh8fZPnOJHNJ5ubn50fdnCRpCSMFepJDGYT5VVV17cHWqapdVTVbVbMzMzOjbE6StIxRznIJ8FHgrqr6m/5KkiQNY5Q99OcDfwS8KMkt3ePsnuqSJK3R0KctVtW/AemxFknSCPykqCQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDVi1JtE70hyT5L7klzSV1GSpLUb5SbRhwAfBF4OnAacn+S0vgqTJK3NKHvovwncV1X3V9VPgU8A5/ZTliRprUYJ9BOB7y6Yf7hrkyRtgHU/KJpkZ5K5JHPz8/NDv87XL/7dHqvaWM85efNB23/1+KMBOHHzk1f1Oicce0RvNf3luc98fPpVz/3l3l53Jac85eixbWvSjKOfn5TRnr/5yENXtd6WVa43rFG+j0MPGbETRrD/d/rXTjx2LNtLVQ33xORM4O1VdVY3fylAVf3VUs+ZnZ2tubm5obYnSf9fJdldVbMrrTfKHvp/AKck2Z7kMOA84PMjvJ4kaQSbhn1iVT2W5M+ALwGHAFdU1R29VSZJWpOhAx2gqr4AfKGnWiRJI/CTopLUCANdkhphoEtSIwx0SWqEgS5JjRj6g0VDbSyZB74z5NO3Ao/2WM56m6Z6p6lWmK56p6lWmK56p6lWGK3eX6mqmZVWGmugjyLJ3Go+KTUppqneaaoVpqveaaoVpqveaaoVxlOvQy6S1AgDXZIaMU2BvmujC1ijaap3mmqF6ap3mmqF6ap3mmqFMdQ7NWPokqTlTdMeuiRpGVMR6JNwM+okJyf5SpI7k9yR5A1d+3FJrk9yb/d1S9eeJO/var4tyRkLXuuCbv17k1ywjjUfkuTmJNd189uT3NjV9MnussckObybv69bvm3Ba1zatd+T5Kx1rHVzkmuS3J3kriRnTmrfJnlT9x7Yk+TqJEdMUt8muSLJviR7FrT11pdJfiPJ7d1z3p9k6DtILFHru7v3wW1JPpNk84JlB+2zpTJiqZ9Ln/UuWPbmJJVkazc//r6tqol+MLg077eBpwOHAbcCp21AHScAZ3TTxwDfYnBz7HcBl3TtlwDv7KbPBr4IBHgecGPXfhxwf/d1Sze9ZZ1q/gvgH4HruvlPAed105cDf9JNvw64vJs+D/hkN31a19+HA9u7n8Mh61TrlcAfd9OHAZsnsW8Z3GbxAeDJC/r0wknqW+AFwBnAngVtvfUl8M1u3XTPfXnPtb4M2NRNv3NBrQftM5bJiKV+Ln3W27WfzOBS4t8Btm5U3/b+i9n3AzgT+NKC+UuBSyegrs8BLwXuAU7o2k4A7ummPwycv2D9e7rl5wMfXtB+wHo91ncScAPwIuC67g3y6IJflMf7tXsjntlNb+rWy+K+Xrhez7UeyyAks6h94vqWJ+6le1zXV9cBZ01a3wLbODAke+nLbtndC9oPWK+PWhct+33gqm76oH3GEhmx3Hu+73qBa4DnAA/yRKCPvW+nYchl4m5G3f3bfDpwI3B8VT3SLfoecHw3vVTd4/p+3gtcDPy8m/8l4L+q6rGDbPfxmrrlP+rWH1et24F54GMZDBF9JMlRTGDfVtVe4D3AQ8AjDPpqN5Pbt/v11ZcndtOL29fLaxnsqbJCTQdrX+4935sk5wJ7q+rWRYvG3rfTEOgTJcnRwKeBN1bVjxcuq8Gf1Q0/bSjJOcC+qtq90bWs0iYG/8Z+qKpOB37CYFjgcRPUt1uAcxn8EXoacBSwY0OLWqNJ6cuVJLkMeAy4aqNrWUqSI4G3AG/d6FpgOgJ9L4Pxqf1O6trGLsmhDML8qqq6tmv+fpITuuUnAPu69qXqHsf383zglUkeBD7BYNjlfcDmJPvvUrVwu4/X1C0/FvjBmGqFwZ7Iw1V1Yzd/DYOAn8S+fQnwQFXNV9XPgGsZ9Pek9u1+ffXl3m56cXuvklwInAO8qvsDNEytP2Dpn0tfnsHgj/ut3e/bScBNSZ46RL2j921fY3br9WCw93Z/12n7D3g8cwPqCPB3wHsXtb+bAw82vaubfgUHHhD5Ztd+HIPx4i3d4wHguHWs+4U8cVD0nzjwANHruuk/5cADd5/qpp/JgQeh7mf9Dop+HTi1m357168T17fAc4E7gCO77V8JvH7S+pZfHEPvrS/5xQN3Z/dc6w7gTmBm0XoH7TOWyYilfi591rto2YM8MYY+9r5dlxDp+8HgaPG3GBzJvmyDavhtBv+m3gbc0j3OZjBOdwNwL/AvC34wAT7Y1Xw7MLvgtV4L3Nc9XrPOdb+QJwL96d0b5r7ujX54135EN39ft/zpC55/Wfc93MMIZzOsos5fB+a6/v1s90afyL4F3gHcDewB/r4LmInpW+BqBuP7P2Pw389FffYlMNt9798GPsCig9k91HofgzHm/b9nl6/UZyyREUv9XPqsd9HyB3ki0Mfet35SVJIaMQ1j6JKkVTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqxP8BhGkglCvcXk0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(np.convolve(np.sum(reward, axis=1), np.ones(1)/1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7H8MssbrU7yB"
   },
   "source": [
    "# Exercise 4: SARSA\n",
    "\n",
    "SARSA is similar to Q-learning, but it is an *on-policy* algorithm: it follows a (stochastic) policy $\\pi_Q$ and updates its estimate towards the value of this policy. One possible choice is:\n",
    "\n",
    "$$\n",
    "\\pi_Q(a|s) = \\frac{ \\exp(\\tau^{-1}Q(s,a))  }{\\sum_{a'}\\exp(\\tau^{-1}Q(s,a')) }\n",
    "$$\n",
    "where $\\tau$ is a \"temperature\" parameter: when $\\tau$ approaches 0, $\\pi_Q(a|s)$ approaches the greedy (deterministic) policy $a \\in \\arg\\max_{a'}Q(s,a')$.\n",
    "\n",
    "At each time $t$, SARSA keeps an estimate $\\hat{Q}_t$ of the true Q function and uses $\\pi_{\\hat{Q}_t}(a|s)$ to choose the action $a_t$. If $\\tau \\to 0$ with a proper rate as $t \\to \\infty$, $\\hat{Q}_t$ converges to $Q$ and $\\pi_{\\hat{Q}_t}(a|s)$ converges to the optimal policy $\\pi^*$. \n",
    "\n",
    "The SARSA update at time $t$ is done as follows:\n",
    "\n",
    "1. In state $s_t$, take action $a_t \\sim \\pi_{\\hat{Q}_t}(a|s_t)$ ;\n",
    "2. Observe $s_{t+1}$ and reward $r_t$;\n",
    "3. Sample the next action $a_{t+1} \\sim \\pi_{\\hat{Q}_t}(a|s_{t+1})$;\n",
    "4. Compute $\\delta_t = r_t + \\gamma \\hat{Q}_t(s_{t+1}, a_{t+1}) - \\hat{Q}_t(s_t, a_t)$\n",
    "5. Update $\\hat{Q}_{t+1}(s, a) = \\hat{Q}_t(s, a) + \\alpha_t(s,a)\\delta_t\\mathbb{1}\\{s=s_t, a=a_t\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMcjhJgHU7yC"
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# SARSA implementation\n",
    "# ------------------------------\n",
    "\n",
    "class Sarsa:\n",
    "    \"\"\"\n",
    "    Implements SARSA algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, gamma, learning_rate=None, tau=1.0): # Again, those are suggestions, you can add more arguments\n",
    "        pass\n",
    "    def act():\n",
    "        pass\n",
    "    def optimize():\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5xwDoN4U7yG"
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Convergence of SARSA\n",
    "# ---------------------------\n",
    "\n",
    "# Create SARSA object\n",
    "sarsa = Sarsa(env, gamma=env.gamma)\n",
    "\n",
    "# Again, you can use Q_opt and pi_opt from value_iteration to check sarsa's convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6Och_7yU7yI"
   },
   "source": [
    "How those two algorithms behave ? \n",
    "Do both of them find the optimal policy ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxCXUzRvU7yI"
   },
   "source": [
    "## Trying other algorithms\n",
    "\n",
    "\n",
    "### Policy iteration\n",
    "Policy iteration is another algorithm to find an optimal policy when the MDP is known:\n",
    "\n",
    "$$\n",
    "\\pi_{n} \\gets \\mathrm{greedy}(V_{\\pi_{n-1}}) \\\\\n",
    "V_{\\pi_n} \\gets \\mbox{policy-evaluation}(\\pi_n)\n",
    "$$\n",
    "For any arbitrary $\\pi_0$, $\\pi_n$ converges to $\\pi^*$.\n",
    "\n",
    "Implement policy iteration and compare it to value iteration.\n",
    "\n",
    "\n",
    "### Stochastic algorithms for policy evaluation\n",
    "\n",
    "Given a policy $\\pi$, implement different stochastic algorithms to estimate its value $V_\\pi$.\n",
    "\n",
    "#### Monte Carlo estimation\n",
    "\n",
    "$$\n",
    "V_\\pi(s) = E\\left[ \\sum_{t=0}^\\infty \\gamma^t r(S_t, A_t, S_{t+1}) | S_0 = s \\right] \\approx \\frac{1}{N} \\sum_{i=1}^N \\sum_{t=0}^{T} \\gamma^t r(s_t^i, a_t^i, s_{t+1}^i) \n",
    "$$\n",
    "\n",
    "\n",
    "#### TD(0): \n",
    "\n",
    "Given a trajectory $ (x_t, x_{t+1}, r_t)_{t\\geq 0} $ , the $t$-th step of TD(0) performs the following calculations:\n",
    "\n",
    "$ \\delta_t = r_t + \\gamma \\hat{V}_t(x_{t+1}) - \\hat{V}_t(x_t)$\n",
    "\n",
    "$ \\hat{V}_{t+1}(x) = \\hat{V}_t(x) + \\alpha_t(x)\\delta_t\\mathbb{1}\\{x=x_t\\}  $ \n",
    "\n",
    "where $\\alpha_t(x_t)$ is the step size and $\\delta_t$ is called *temporal difference*.\n",
    "\n",
    "#### TD($\\lambda$):\n",
    "\n",
    "Given a trajectory $ (x_t, x_{t+1}, r_t)_{t\\geq 0} $, the $t$-th step of TD($\\lambda$) performs the following calculations:\n",
    "\n",
    "$ \\delta_t = r_t + \\gamma \\hat{V}_t(x_{t+1}) - \\hat{V}_t(x_t)$\n",
    "\n",
    "$ z_{t+1}(x) = \\mathbb{1}\\{x=x_t\\} + \\gamma \\lambda z_t(x)  $ \n",
    "\n",
    "$ \\hat{V}_{t+1}(x) = \\hat{V}_t(x) + \\alpha_t(x)\\delta_t z_{t+1}(x)  $ \n",
    "\n",
    "$ z_0(x) = 0 $\n",
    "\n",
    "for all states $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDz1KngyU7yJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "RL.DP+QLearning+SARSA.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
